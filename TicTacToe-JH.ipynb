{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog post\n",
    "## http://datascience8.edublogs.org/2018/07/03/iterative-value-function-reinforcement-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LENGTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "  def __init__(self):\n",
    "    self.eps = 0.1\n",
    "    self.alpha = 0.5\n",
    "    self.verbose = False\n",
    "    self.state_history = []\n",
    "  def set_epsalf(self, eps, alpha):\n",
    "    self.eps = eps\n",
    "    self.alpha = alpha\n",
    "    \n",
    "  def setV(self, V):\n",
    "    self.V = V\n",
    "\n",
    "  def set_symbol(self, sym):\n",
    "    self.sym = sym\n",
    "\n",
    "  def set_verbose(self, v):\n",
    "    # if true, will print values for each position on the board\n",
    "    self.verbose = v\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "  def reset_history(self):\n",
    "    self.state_history = []\n",
    "\n",
    "  def take_action(self, env):\n",
    "    # choose an action based on epsilon-greedy strategy\n",
    "    r = np.random.rand()\n",
    "    best_state = None\n",
    "    if r < self.eps:\n",
    "      # take a random action\n",
    "      if self.verbose:\n",
    "        print(\"Taking a random action\")\n",
    "\n",
    "      possible_moves = []\n",
    "      for i in range(LENGTH):\n",
    "        for j in range(LENGTH):\n",
    "          if env.is_empty(i, j):\n",
    "            possible_moves.append((i, j))\n",
    "      idx = np.random.choice(len(possible_moves))\n",
    "      next_move = possible_moves[idx]\n",
    "    else:\n",
    "      # choose the best action based on current values of states\n",
    "      # loop through all possible moves, get their values\n",
    "      # keep track of the best value\n",
    "      pos2value = {} # for debugging\n",
    "      next_move = None\n",
    "      best_value = -1\n",
    "      for i in range(LENGTH):\n",
    "        for j in range(LENGTH):\n",
    "          if env.is_empty(i, j):\n",
    "            # what is the state if we made this move?\n",
    "            env.board[i,j] = self.sym\n",
    "            state = env.get_state()\n",
    "            env.board[i,j] = 0 # don't forget to change it back!\n",
    "            pos2value[(i,j)] = self.V[state]\n",
    "            if self.V[state] > best_value:\n",
    "              best_value = self.V[state]\n",
    "              best_state = state\n",
    "              next_move = (i, j)\n",
    "\n",
    "      # if verbose, draw the board w/ the values\n",
    "      if self.verbose:\n",
    "        print(\"Taking a greedy action\")\n",
    "        for i in range(LENGTH):\n",
    "          print(\"------------------\")\n",
    "          for j in range(LENGTH):\n",
    "            if env.is_empty(i, j):\n",
    "              # print the value\n",
    "              print(\" %.2f|\" % pos2value[(i,j)], end=\"\")\n",
    "            else:\n",
    "              print(\"  \", end=\"\")\n",
    "              if env.board[i,j] == env.x:\n",
    "                print(\"x  |\", end=\"\")\n",
    "              elif env.board[i,j] == env.o:\n",
    "                print(\"o  |\", end=\"\")\n",
    "              else:\n",
    "                print(\"   |\", end=\"\")\n",
    "          print(\"\")\n",
    "        print(\"------------------\")\n",
    "\n",
    "    # make the move\n",
    "    env.board[next_move[0], next_move[1]] = self.sym\n",
    "\n",
    "  def update_state_history(self, s):\n",
    "    # cannot put this in take_action, because take_action only happens\n",
    "    # once every other iteration for each player\n",
    "    # state history needs to be updated every iteration\n",
    "    # s = env.get_state() # don't want to do this twice so pass it in\n",
    "    self.state_history.append(s)\n",
    "\n",
    "  def update(self, env):\n",
    "    # we want to BACKTRACK over the states, so that:\n",
    "    # V(prev_state) = V(prev_state) + alpha*(V(next_state) - V(prev_state))\n",
    "    # where V(next_state) = reward if it's the most current state\n",
    "    #\n",
    "    # NOTE: we ONLY do this at the end of an episode\n",
    "    # not so for all the algorithms we will study\n",
    "    reward = env.reward(self.sym)\n",
    "    target = reward\n",
    "    for prev in reversed(self.state_history):\n",
    "      value = self.V[prev] + self.alpha*(target - self.V[prev])\n",
    "      self.V[prev] = value\n",
    "      target = value\n",
    "    self.reset_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this class represents a tic-tac-toe game\n",
    "# is a CS101-type of project\n",
    "class Environment:\n",
    "  def __init__(self):\n",
    "    self.board = np.zeros((LENGTH, LENGTH))\n",
    "    self.x = -1 # represents an x on the board, player 1\n",
    "    self.o = 1 # represents an o on the board, player 2\n",
    "    self.winner = None\n",
    "    self.ended = False\n",
    "    self.num_states = 3**(LENGTH*LENGTH)\n",
    "\n",
    "  def is_empty(self, i, j):\n",
    "    return self.board[i,j] == 0\n",
    "\n",
    "  def reward(self, sym):\n",
    "    # no reward until game is over\n",
    "    if not self.game_over():\n",
    "      return 0\n",
    "\n",
    "    # if we get here, game is over\n",
    "    # sym will be self.x or self.o\n",
    "    return 1 if self.winner == sym else 0\n",
    "\n",
    "  def get_state(self):\n",
    "    # returns the current state, represented as an int\n",
    "    # from 0...|S|-1, where S = set of all possible states\n",
    "    # |S| = 3^(BOARD SIZE), since each cell can have 3 possible values - empty, x, o\n",
    "    # some states are not possible, e.g. all cells are x, but we ignore that detail\n",
    "    # this is like finding the integer represented by a base-3 number\n",
    "    k = 0\n",
    "    h = 0\n",
    "    for i in range(LENGTH):\n",
    "      for j in range(LENGTH):\n",
    "        if self.board[i,j] == 0:\n",
    "          v = 0\n",
    "        elif self.board[i,j] == self.x:\n",
    "          v = 1\n",
    "        elif self.board[i,j] == self.o:\n",
    "          v = 2\n",
    "        h += (3**k) * v\n",
    "        k += 1\n",
    "    return h\n",
    "\n",
    "  def game_over(self, force_recalculate=False):\n",
    "    # returns true if game over (a player has won or it's a draw)\n",
    "    # otherwise returns false\n",
    "    # also sets 'winner' instance variable and 'ended' instance variable\n",
    "    if not force_recalculate and self.ended:\n",
    "      return self.ended\n",
    "    \n",
    "    # check rows\n",
    "    for i in range(LENGTH):\n",
    "      for player in (self.x, self.o):\n",
    "        if self.board[i].sum() == player*LENGTH:\n",
    "          self.winner = player\n",
    "          self.ended = True\n",
    "          return True\n",
    "\n",
    "    # check columns\n",
    "    for j in range(LENGTH):\n",
    "      for player in (self.x, self.o):\n",
    "        if self.board[:,j].sum() == player*LENGTH:\n",
    "          self.winner = player\n",
    "          self.ended = True\n",
    "          return True\n",
    "\n",
    "    # check diagonals\n",
    "    for player in (self.x, self.o):\n",
    "      # top-left -> bottom-right diagonal\n",
    "      if self.board.trace() == player*LENGTH:\n",
    "        self.winner = player\n",
    "        self.ended = True\n",
    "        return True\n",
    "      # top-right -> bottom-left diagonal\n",
    "        #flips the board\n",
    "      if np.fliplr(self.board).trace() == player*LENGTH:\n",
    "        self.winner = player\n",
    "        self.ended = True\n",
    "        return True\n",
    "\n",
    "    # check if draw\n",
    "    if np.all((self.board == 0) == False):\n",
    "      # winner stays None\n",
    "      self.winner = None\n",
    "      self.ended = True\n",
    "      return True\n",
    "\n",
    "    # game is not over\n",
    "    self.winner = None\n",
    "    return False\n",
    "\n",
    "  def is_draw(self):\n",
    "    return self.ended and self.winner is None\n",
    "\n",
    "  # Example board\n",
    "  # -------------\n",
    "  # | x |   |   |\n",
    "  # -------------\n",
    "  # |   |   |   |\n",
    "  # -------------\n",
    "  # |   |   | o |\n",
    "  # -------------\n",
    "  def draw_board(self):\n",
    "    for i in range(LENGTH):\n",
    "      print(\"-------------\")\n",
    "      for j in range(LENGTH):\n",
    "        print(\"  \", end=\"\")\n",
    "        if self.board[i,j] == self.x:\n",
    "          print(\"x \", end=\"\")\n",
    "        elif self.board[i,j] == self.o:\n",
    "          print(\"o \", end=\"\")\n",
    "        else:\n",
    "          print(\"  \", end=\"\")\n",
    "      print(\"\")\n",
    "    print(\"-------------\")\n",
    "\n",
    "\n",
    "\n",
    "class Human:\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def set_symbol(self, sym):\n",
    "    self.sym = sym\n",
    "\n",
    "  def take_action(self, env):\n",
    "    while True:\n",
    "      # break if we make a legal move\n",
    "      move = input(\"Enter coordinates i,j for your next move (i,j=0..2): \")\n",
    "      i, j = move.split(',')\n",
    "      i = int(i)\n",
    "      j = int(j)\n",
    "      if env.is_empty(i, j):\n",
    "        env.board[i,j] = self.sym\n",
    "        break\n",
    "\n",
    "  def update(self, env):\n",
    "    pass\n",
    "\n",
    "  def update_state_history(self, s):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recursive function that will return all\n",
    "# possible states (as ints) and who the corresponding winner is for those states (if any)\n",
    "# (i, j) refers to the next cell on the board to permute (we need to try -1, 0, 1)\n",
    "# impossible games are ignored, i.e. 3x's and 3o's in a row simultaneously\n",
    "# since that will never happen in a real game\n",
    "def get_state_hash_and_winner(env, i=0, j=0):\n",
    "  results = []\n",
    "\n",
    "  for v in (0, env.x, env.o):\n",
    "    env.board[i,j] = v # if empty board it should already be 0\n",
    "    if j == 2:\n",
    "      # j goes back to 0, increase i, unless i = 2, then we are done\n",
    "      if i == 2:\n",
    "        # the board is full, collect results and return\n",
    "        state = env.get_state()\n",
    "        ended = env.game_over(force_recalculate=True)\n",
    "        winner = env.winner\n",
    "        results.append((state, winner, ended))\n",
    "      else:\n",
    "        results += get_state_hash_and_winner(env, i + 1, 0)\n",
    "    else:\n",
    "      # increment j, i stays the same\n",
    "      results += get_state_hash_and_winner(env, i, j + 1)\n",
    "\n",
    "  return results\n",
    "\n",
    "# play all possible games\n",
    "# need to also store if game is over or not\n",
    "# because we are going to initialize those values to 0.5\n",
    "# NOTE: THIS IS SLOW because MANY possible games lead to the same outcome / state\n",
    "# def get_state_hash_and_winner(env, turn='x'):\n",
    "#   results = []\n",
    "\n",
    "#   state = env.get_state()\n",
    "#   # board_before = env.board.copy()\n",
    "#   ended = env.game_over(force_recalculate=True)\n",
    "#   winner = env.winner\n",
    "#   results.append((state, winner, ended))\n",
    "\n",
    "#   # DEBUG\n",
    "#   # if ended:\n",
    "#   #   if winner is not None and env.win_type.startswith('col'):\n",
    "#   #     env.draw_board()\n",
    "#   #     print \"Winner:\", 'x' if winner == -1 else 'o', env.win_type\n",
    "#   #     print \"\\n\\n\"\n",
    "#   #     assert(np.all(board_before == env.board))\n",
    "\n",
    "#   if not ended:\n",
    "#     if turn == 'x':\n",
    "#       sym = env.x\n",
    "#       next_sym = 'o'\n",
    "#     else:\n",
    "#       sym = env.o\n",
    "#       next_sym = 'x'\n",
    "\n",
    "#     for i in xrange(LENGTH):\n",
    "#       for j in xrange(LENGTH):\n",
    "#         if env.is_empty(i, j):\n",
    "#           env.board[i,j] = sym\n",
    "#           results += get_state_hash_and_winner(env, next_sym)\n",
    "#           env.board[i,j] = 0 # reset it\n",
    "#   return results\n",
    "\n",
    "\n",
    "def initialV_x(env, state_winner_triples):\n",
    "  # initialize state values as follows\n",
    "  # if x wins, V(s) = 1\n",
    "  # if x loses or draw, V(s) = 0\n",
    "  # otherwise, V(s) = 0.5\n",
    "  V = np.zeros(env.num_states)\n",
    "  for state, winner, ended in state_winner_triples:\n",
    "    if ended:\n",
    "      if winner == env.x:\n",
    "        v = 1\n",
    "      else:\n",
    "        v = 0\n",
    "    else:\n",
    "      v = 0.5\n",
    "    V[state] = v\n",
    "  return V\n",
    "\n",
    "\n",
    "def initialV_o(env, state_winner_triples):\n",
    "  # this is (almost) the opposite of initial V for player x\n",
    "  # since everywhere where x wins (1), o loses (0)\n",
    "  # but a draw is still 0 for o\n",
    "  V = np.zeros(env.num_states)\n",
    "  for state, winner, ended in state_winner_triples:\n",
    "    if ended:\n",
    "      if winner == env.o:\n",
    "        v = 1\n",
    "      else:\n",
    "        v = 0\n",
    "    else:\n",
    "      v = 0.5\n",
    "    V[state] = v\n",
    "  return V\n",
    "\n",
    "\n",
    "def play_game(p1, p2, env, draw=False):\n",
    "  # loops until the game is over\n",
    "  current_player = None\n",
    "  while not env.game_over():\n",
    "    # alternate between players\n",
    "    # p1 always starts first\n",
    "    if current_player == p1:\n",
    "      current_player = p2\n",
    "    else:\n",
    "      current_player = p1\n",
    "\n",
    "    # draw the board before the user who wants to see it makes a move\n",
    "    if draw:\n",
    "      if draw == 1 and current_player == p1:\n",
    "        env.draw_board()\n",
    "      if draw == 2 and current_player == p2:\n",
    "        env.draw_board()\n",
    "\n",
    "    # current player makes a move\n",
    "    current_player.take_action(env)\n",
    "\n",
    "    # update state histories\n",
    "    state = env.get_state()\n",
    "    p1.update_state_history(state)\n",
    "    p2.update_state_history(state)\n",
    "\n",
    "  if draw:\n",
    "    env.draw_board()\n",
    "\n",
    "  # do the value function update\n",
    "  p1.update(env)\n",
    "  p2.update(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run everything with default epsilon and alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13600\n",
      "13800\n",
      "14000\n",
      "14200\n",
      "14400\n",
      "14600\n",
      "14800\n",
      "15000\n",
      "15200\n",
      "15400\n",
      "15600\n",
      "15800\n",
      "16000\n",
      "16200\n",
      "16400\n",
      "16600\n",
      "16800\n",
      "17000\n",
      "17200\n",
      "17400\n",
      "17600\n",
      "17800\n",
      "18000\n",
      "18200\n",
      "18400\n",
      "18600\n",
      "18800\n",
      "19000\n",
      "19200\n",
      "19400\n",
      "19600\n",
      "19800\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.72| 0.65| 0.73|\n",
      "------------------\n",
      " 0.37| 0.75| 0.55|\n",
      "------------------\n",
      " 0.68| 0.69| 0.77|\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a random action\n",
      "-------------\n",
      "  o         \n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.43|  o  |\n",
      "------------------\n",
      "  x  | 0.12| 0.25|\n",
      "------------------\n",
      " 0.25| 0.25|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  x  |  o  |\n",
      "------------------\n",
      "  x  |  o  | 0.03|\n",
      "------------------\n",
      " 0.05| 0.06|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "  x   o     \n",
      "-------------\n",
      "      x   x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,0\n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "  x   o     \n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "Play again? [Y/n]: n\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # train the agent\n",
    "  p1 = Agent()\n",
    "  p2 = Agent()\n",
    "\n",
    "  # set initial V for p1 and p2\n",
    "  env = Environment()\n",
    "  state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "\n",
    "  Vx = initialV_x(env, state_winner_triples)\n",
    "  p1.setV(Vx)\n",
    "  Vo = initialV_o(env, state_winner_triples)\n",
    "  p2.setV(Vo)\n",
    "\n",
    "  # give each player their symbol\n",
    "  p1.set_symbol(env.x)\n",
    "  p2.set_symbol(env.o)\n",
    "\n",
    "  T = 20000\n",
    "  for t in range(T):\n",
    "    if t % 200 == 0:\n",
    "      print(t)\n",
    "    play_game(p1, p2, Environment())\n",
    "\n",
    "  # play human vs. agent\n",
    "  # do you think the agent learned to play the game well?\n",
    "  human = Human()\n",
    "  human.set_symbol(env.o)\n",
    "  while True:\n",
    "    p1.set_verbose(True)\n",
    "    play_game(p1, human, Environment(), draw=2)\n",
    "    # I made the agent player 1 because I wanted to see if it would\n",
    "    # select the center as its starting move. If you want the agent\n",
    "    # to go second you can switch the human and AI.\n",
    "    answer = input(\"Play again? [Y/n]: \")\n",
    "    if answer and answer.lower()[0] == 'n':\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent took a random action, causing me to win in the long run. Lets reduce the random actions when playing the human "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with many random actions (eps=0.8) and high learning rate (alpha = 0.9)\n",
    "## Play with the human the agent will be more greedy (eps=0.001) and default alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13600\n",
      "13800\n",
      "14000\n",
      "14200\n",
      "14400\n",
      "14600\n",
      "14800\n",
      "15000\n",
      "15200\n",
      "15400\n",
      "15600\n",
      "15800\n",
      "16000\n",
      "16200\n",
      "16400\n",
      "16600\n",
      "16800\n",
      "17000\n",
      "17200\n",
      "17400\n",
      "17600\n",
      "17800\n",
      "18000\n",
      "18200\n",
      "18400\n",
      "18600\n",
      "18800\n",
      "19000\n",
      "19200\n",
      "19400\n",
      "19600\n",
      "19800\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.12| 0.12| 0.40|\n",
      "------------------\n",
      " 0.16| 0.80| 0.10|\n",
      "------------------\n",
      " 0.78| 0.16| 0.65|\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.33| 0.13| 0.26|\n",
      "------------------\n",
      " 0.01|  x  | 0.99|\n",
      "------------------\n",
      " 0.83| 0.99|  o  |\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "      x   o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.90|  o  | 0.11|\n",
      "------------------\n",
      " 0.90|  x  | 0.90|\n",
      "------------------\n",
      " 0.08|  x  |  o  |\n",
      "------------------\n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "      x   x \n",
      "-------------\n",
      "      x   o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.00|  o  | 0.10|\n",
      "------------------\n",
      "  o  |  x  |  x  |\n",
      "------------------\n",
      " 0.00|  x  |  o  |\n",
      "------------------\n",
      "-------------\n",
      "      o   x \n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "      x   o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.00|  o  |  x  |\n",
      "------------------\n",
      "  o  |  x  |  x  |\n",
      "------------------\n",
      "  o  |  x  |  o  |\n",
      "------------------\n",
      "-------------\n",
      "  x   o   x \n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.12| 0.12| 0.40|\n",
      "------------------\n",
      " 0.16| 0.85| 0.10|\n",
      "------------------\n",
      " 0.78| 0.16| 0.65|\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.33| 0.13| 0.26|\n",
      "------------------\n",
      " 0.01|  x  | 0.99|\n",
      "------------------\n",
      " 0.83| 0.82|  o  |\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x   x \n",
      "-------------\n",
      "          o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.09| 0.83| 0.89|\n",
      "------------------\n",
      "  o  |  x  |  x  |\n",
      "------------------\n",
      " 0.83| 0.03|  o  |\n",
      "------------------\n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "          o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.99|  x  |\n",
      "------------------\n",
      "  o  |  x  |  x  |\n",
      "------------------\n",
      " 1.00| 1.00|  o  |\n",
      "------------------\n",
      "-------------\n",
      "  o       x \n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "  x       o \n",
      "-------------\n",
      "Play again? [Y/n]: n\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # train the agent\n",
    "  p1 = Agent()\n",
    "  p2 = Agent()\n",
    "\n",
    "  # set initial V for p1 and p2\n",
    "  env = Environment()\n",
    "  state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "\n",
    "  Vx = initialV_x(env, state_winner_triples)\n",
    "  p1.setV(Vx)\n",
    "  Vo = initialV_o(env, state_winner_triples)\n",
    "  p2.setV(Vo)\n",
    "\n",
    "  # give each player their symbol\n",
    "  p1.set_symbol(env.x)\n",
    "  p2.set_symbol(env.o)\n",
    "\n",
    "  #set epsilons\n",
    "  p1.set_epsalf(0.8, 0.9)\n",
    "  p2.set_epsalf(0.8, 0.9)\n",
    "\n",
    "  T = 20000\n",
    "  for t in range(T):\n",
    "    if t % 500 == 0:\n",
    "      print(t)\n",
    "    play_game(p1, p2, Environment())\n",
    "\n",
    "  # play human vs. agent\n",
    "  # do you think the agent learned to play the game well?\n",
    "  human = Human()\n",
    "  human.set_symbol(env.o)\n",
    "  while True:\n",
    "    p1.set_verbose(True)\n",
    "    p1.set_epsalf(0.001, 0.5)\n",
    "    play_game(p1, human, Environment(), draw=2)\n",
    "    # I made the agent player 1 because I wanted to see if it would\n",
    "    # select the center as its starting move. If you want the agent\n",
    "    # to go second you can switch the human and AI.\n",
    "    answer = input(\"Play again? [Y/n]: \")\n",
    "    if answer and answer.lower()[0] == 'n':\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore 50% of the time (Eps=.5) while training, then exploit when playing human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.49| 0.51| 0.41|\n",
      "------------------\n",
      " 0.47| 0.82| 0.42|\n",
      "------------------\n",
      " 0.56| 0.63| 0.60|\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.65| 0.61| 0.90|\n",
      "------------------\n",
      " 0.60|  x  | 0.67|\n",
      "------------------\n",
      " 0.58| 0.78|  o  |\n",
      "------------------\n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "          o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.24| 0.07|  x  |\n",
      "------------------\n",
      " 0.51|  x  | 0.15|\n",
      "------------------\n",
      "  o  | 0.72|  o  |\n",
      "------------------\n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 1.00|  x  |\n",
      "------------------\n",
      " 1.00|  x  | 0.01|\n",
      "------------------\n",
      "  o  |  x  |  o  |\n",
      "------------------\n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.49| 0.51| 0.41|\n",
      "------------------\n",
      " 0.47| 0.82| 0.42|\n",
      "------------------\n",
      " 0.56| 0.63| 0.60|\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.93| 0.71|\n",
      "------------------\n",
      " 0.85|  x  | 0.77|\n",
      "------------------\n",
      " 0.33| 0.46| 0.68|\n",
      "------------------\n",
      "-------------\n",
      "  o   x     \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  x  | 0.01|\n",
      "------------------\n",
      " 0.95|  x  | 0.18|\n",
      "------------------\n",
      "  o  | 1.00| 0.55|\n",
      "------------------\n",
      "-------------\n",
      "  o   x     \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "  o   x     \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.49| 0.51| 0.41|\n",
      "------------------\n",
      " 0.47| 0.86| 0.42|\n",
      "------------------\n",
      " 0.56| 0.63| 0.60|\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.61| 0.69| 0.76|\n",
      "------------------\n",
      " 0.79|  x  | 0.75|\n",
      "------------------\n",
      " 0.67|  o  | 0.94|\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "      o   x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.52| 0.84|\n",
      "------------------\n",
      " 0.40|  x  | 0.95|\n",
      "------------------\n",
      " 0.67|  o  |  x  |\n",
      "------------------\n",
      "-------------\n",
      "  o         \n",
      "-------------\n",
      "      x   x \n",
      "-------------\n",
      "      o   x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.01| 1.00|\n",
      "------------------\n",
      "  o  |  x  |  x  |\n",
      "------------------\n",
      " 0.24|  o  |  x  |\n",
      "------------------\n",
      "-------------\n",
      "  o       x \n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "      o   x \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.49| 0.51| 0.41|\n",
      "------------------\n",
      " 0.47| 0.86| 0.42|\n",
      "------------------\n",
      " 0.56| 0.63| 0.60|\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.96| 0.71|\n",
      "------------------\n",
      " 0.85|  x  | 0.77|\n",
      "------------------\n",
      " 0.33| 0.46| 0.68|\n",
      "------------------\n",
      "-------------\n",
      "  o   x     \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  x  | 0.52|\n",
      "------------------\n",
      " 0.77|  x  | 0.47|\n",
      "------------------\n",
      " 0.70|  o  | 0.52|\n",
      "------------------\n",
      "-------------\n",
      "  o   x     \n",
      "-------------\n",
      "  x   x     \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  x  | 0.17|\n",
      "------------------\n",
      "  x  |  x  |  o  |\n",
      "------------------\n",
      " 0.72|  o  | 0.00|\n",
      "------------------\n",
      "-------------\n",
      "  o   x     \n",
      "-------------\n",
      "  x   x   o \n",
      "-------------\n",
      "  x   o     \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  x  |  o  |\n",
      "------------------\n",
      "  x  |  x  |  o  |\n",
      "------------------\n",
      "  x  |  o  | 0.00|\n",
      "------------------\n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "  x   x   o \n",
      "-------------\n",
      "  x   o   x \n",
      "-------------\n",
      "Play again? [Y/n]: n\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # train the agent\n",
    "  p1 = Agent()\n",
    "  p2 = Agent()\n",
    "\n",
    "  # set initial V for p1 and p2\n",
    "  env = Environment()\n",
    "  state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "\n",
    "  Vx = initialV_x(env, state_winner_triples)\n",
    "  p1.setV(Vx)\n",
    "  Vo = initialV_o(env, state_winner_triples)\n",
    "  p2.setV(Vo)\n",
    "\n",
    "  # give each player their symbol\n",
    "  p1.set_symbol(env.x)\n",
    "  p2.set_symbol(env.o)\n",
    "\n",
    "  #set epsilons\n",
    "  p1.set_epsalf(0.5, 0.5)\n",
    "  p2.set_epsalf(0.5, 0.5)\n",
    "\n",
    "  T = 20000\n",
    "  for t in range(T):\n",
    "    if t % 5000 == 0:\n",
    "      print(t)\n",
    "    play_game(p1, p2, Environment())\n",
    "\n",
    "  # play human vs. agent\n",
    "  # do you think the agent learned to play the game well?\n",
    "  human = Human()\n",
    "  human.set_symbol(env.o)\n",
    "  while True:\n",
    "    p1.set_verbose(True)\n",
    "    p1.set_epsalf(0.001, 0.5)\n",
    "    play_game(p1, human, Environment(), draw=2)\n",
    "    # I made the agent player 1 because I wanted to see if it would\n",
    "    # select the center as its starting move. If you want the agent\n",
    "    # to go second you can switch the human and AI.\n",
    "    answer = input(\"Play again? [Y/n]: \")\n",
    "    if answer and answer.lower()[0] == 'n':\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The agent seems pretty smart!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with default epsilon, but a very low learning rate (alpha=0.05)\n",
    "#### This will effect how the agent updates its learned rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.83| 0.50| 0.51|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.50| 0.50| 0.56|\n",
      "------------------\n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  | 0.48| 0.50|\n",
      "------------------\n",
      " 0.48|  o  | 0.50|\n",
      "------------------\n",
      " 0.48| 0.49| 0.70|\n",
      "------------------\n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  | 0.29| 0.94|\n",
      "------------------\n",
      " 0.31|  o  | 0.24|\n",
      "------------------\n",
      "  o  | 0.21|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  x       x \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "  o       x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  |  o  |  x  |\n",
      "------------------\n",
      " 0.28|  o  | 1.00|\n",
      "------------------\n",
      "  o  | 0.49|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  x   o   x \n",
      "-------------\n",
      "      o   x \n",
      "-------------\n",
      "  o       x \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.81| 0.50| 0.51|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.50| 0.50| 0.56|\n",
      "------------------\n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  | 0.48| 0.50|\n",
      "------------------\n",
      " 0.48|  o  | 0.50|\n",
      "------------------\n",
      " 0.48| 0.49| 0.83|\n",
      "------------------\n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  | 0.28|  o  |\n",
      "------------------\n",
      " 0.19|  o  | 0.26|\n",
      "------------------\n",
      " 0.97| 0.29|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  x       o \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "  x       x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  |  o  |  o  |\n",
      "------------------\n",
      " 1.00|  o  | 0.41|\n",
      "------------------\n",
      "  x  | 1.00|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  x   o   o \n",
      "-------------\n",
      "  x   o     \n",
      "-------------\n",
      "  x       x \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.82| 0.50| 0.51|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.50| 0.50| 0.56|\n",
      "------------------\n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  | 0.50| 0.93|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.53| 0.50|  o  |\n",
      "------------------\n",
      "-------------\n",
      "  x       x \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "          o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  | 1.00|  x  |\n",
      "------------------\n",
      " 0.60|  o  | 0.45|\n",
      "------------------\n",
      " 0.57| 0.50|  o  |\n",
      "------------------\n",
      "-------------\n",
      "  x   x   x \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "          o \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.88| 0.50| 0.51|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.50| 0.50| 0.56|\n",
      "------------------\n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  | 0.50| 0.95|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.53| 0.50|  o  |\n",
      "------------------\n",
      "-------------\n",
      "  x       x \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "          o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  |  o  |  x  |\n",
      "------------------\n",
      " 0.49| 0.49| 0.50|\n",
      "------------------\n",
      " 0.96| 0.50|  o  |\n",
      "------------------\n",
      "-------------\n",
      "  x   o   x \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "  x       o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  x  |  o  |  x  |\n",
      "------------------\n",
      " 1.00|  o  | 0.30|\n",
      "------------------\n",
      "  x  | 0.52|  o  |\n",
      "------------------\n",
      "-------------\n",
      "  x   o   x \n",
      "-------------\n",
      "  x   o     \n",
      "-------------\n",
      "  x       o \n",
      "-------------\n",
      "Play again? [Y/n]: n\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # train the agent\n",
    "  p1 = Agent()\n",
    "  p2 = Agent()\n",
    "\n",
    "  # set initial V for p1 and p2\n",
    "  env = Environment()\n",
    "  state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "\n",
    "  Vx = initialV_x(env, state_winner_triples)\n",
    "  p1.setV(Vx)\n",
    "  Vo = initialV_o(env, state_winner_triples)\n",
    "  p2.setV(Vo)\n",
    "\n",
    "  # give each player their symbol\n",
    "  p1.set_symbol(env.x)\n",
    "  p2.set_symbol(env.o)\n",
    "\n",
    "  #set epsilons\n",
    "  p1.set_epsalf(0.1, 0.05)\n",
    "  p2.set_epsalf(0.1, 0.05)\n",
    "\n",
    "  T = 20000\n",
    "  for t in range(T):\n",
    "    if t % 5000 == 0:\n",
    "      print(t)\n",
    "    play_game(p1, p2, Environment())\n",
    "\n",
    "  # play human vs. agent\n",
    "  # do you think the agent learned to play the game well?\n",
    "  human = Human()\n",
    "  human.set_symbol(env.o)\n",
    "  while True:\n",
    "    p1.set_verbose(True)\n",
    "    p1.set_epsalf(0.001, 0.5)\n",
    "    play_game(p1, human, Environment(), draw=2)\n",
    "    # I made the agent player 1 because I wanted to see if it would\n",
    "    # select the center as its starting move. If you want the agent\n",
    "    # to go second you can switch the human and AI.\n",
    "    answer = input(\"Play again? [Y/n]: \")\n",
    "    if answer and answer.lower()[0] == 'n':\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It looks like having a 10% exploration rate and a slow/cautious learning rate makes the machine very smart! I can't beat it playing second..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set human to play first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recursive function that will return all\n",
    "# possible states (as ints) and who the corresponding winner is for those states (if any)\n",
    "# (i, j) refers to the next cell on the board to permute (we need to try -1, 0, 1)\n",
    "# impossible games are ignored, i.e. 3x's and 3o's in a row simultaneously\n",
    "# since that will never happen in a real game\n",
    "def get_state_hash_and_winner(env, i=0, j=0):\n",
    "  results = []\n",
    "\n",
    "  for v in (0, env.x, env.o):\n",
    "    env.board[i,j] = v # if empty board it should already be 0\n",
    "    if j == 2:\n",
    "      # j goes back to 0, increase i, unless i = 2, then we are done\n",
    "      if i == 2:\n",
    "        # the board is full, collect results and return\n",
    "        state = env.get_state()\n",
    "        ended = env.game_over(force_recalculate=True)\n",
    "        winner = env.winner\n",
    "        results.append((state, winner, ended))\n",
    "      else:\n",
    "        results += get_state_hash_and_winner(env, i + 1, 0)\n",
    "    else:\n",
    "      # increment j, i stays the same\n",
    "      results += get_state_hash_and_winner(env, i, j + 1)\n",
    "\n",
    "  return results\n",
    "\n",
    "# play all possible games\n",
    "# need to also store if game is over or not\n",
    "# because we are going to initialize those values to 0.5\n",
    "# NOTE: THIS IS SLOW because MANY possible games lead to the same outcome / state\n",
    "# def get_state_hash_and_winner(env, turn='x'):\n",
    "#   results = []\n",
    "\n",
    "#   state = env.get_state()\n",
    "#   # board_before = env.board.copy()\n",
    "#   ended = env.game_over(force_recalculate=True)\n",
    "#   winner = env.winner\n",
    "#   results.append((state, winner, ended))\n",
    "\n",
    "#   # DEBUG\n",
    "#   # if ended:\n",
    "#   #   if winner is not None and env.win_type.startswith('col'):\n",
    "#   #     env.draw_board()\n",
    "#   #     print \"Winner:\", 'x' if winner == -1 else 'o', env.win_type\n",
    "#   #     print \"\\n\\n\"\n",
    "#   #     assert(np.all(board_before == env.board))\n",
    "\n",
    "#   if not ended:\n",
    "#     if turn == 'x':\n",
    "#       sym = env.x\n",
    "#       next_sym = 'o'\n",
    "#     else:\n",
    "#       sym = env.o\n",
    "#       next_sym = 'x'\n",
    "\n",
    "#     for i in xrange(LENGTH):\n",
    "#       for j in xrange(LENGTH):\n",
    "#         if env.is_empty(i, j):\n",
    "#           env.board[i,j] = sym\n",
    "#           results += get_state_hash_and_winner(env, next_sym)\n",
    "#           env.board[i,j] = 0 # reset it\n",
    "#   return results\n",
    "\n",
    "\n",
    "def initialV_x(env, state_winner_triples):\n",
    "  # initialize state values as follows\n",
    "  # if x wins, V(s) = 1\n",
    "  # if x loses or draw, V(s) = 0\n",
    "  # otherwise, V(s) = 0.5\n",
    "  V = np.zeros(env.num_states)\n",
    "  for state, winner, ended in state_winner_triples:\n",
    "    if ended:\n",
    "      if winner == env.x:\n",
    "        v = 1\n",
    "      else:\n",
    "        v = 0\n",
    "    else:\n",
    "      v = 0.5\n",
    "    V[state] = v\n",
    "  return V\n",
    "\n",
    "\n",
    "def initialV_o(env, state_winner_triples):\n",
    "  # this is (almost) the opposite of initial V for player x\n",
    "  # since everywhere where x wins (1), o loses (0)\n",
    "  # but a draw is still 0 for o\n",
    "  V = np.zeros(env.num_states)\n",
    "  for state, winner, ended in state_winner_triples:\n",
    "    if ended:\n",
    "      if winner == env.o:\n",
    "        v = 1\n",
    "      else:\n",
    "        v = 0\n",
    "    else:\n",
    "      v = 0.5\n",
    "    V[state] = v\n",
    "  return V\n",
    "\n",
    "\n",
    "def play_game(p1, p2, env, draw=False):\n",
    "  # loops until the game is over\n",
    "  current_player = None\n",
    "  while not env.game_over():\n",
    "    # alternate between players\n",
    "    # p1 always starts first\n",
    "    if current_player == p1:\n",
    "      current_player = p2\n",
    "    else:\n",
    "      current_player = p1\n",
    "\n",
    "    # draw the board before the user who wants to see it makes a move\n",
    "    if draw:\n",
    "      if draw == 1 and current_player == p1:\n",
    "        env.draw_board()\n",
    "      if draw == 2 and current_player == p1:\n",
    "        env.draw_board()\n",
    "\n",
    "    # current player makes a move\n",
    "    current_player.take_action(env)\n",
    "\n",
    "    # update state histories\n",
    "    state = env.get_state()\n",
    "    p1.update_state_history(state)\n",
    "    p2.update_state_history(state)\n",
    "\n",
    "  if draw:\n",
    "    env.draw_board()\n",
    "\n",
    "  # do the value function update\n",
    "  p1.update(env)\n",
    "  p2.update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.50| 0.51|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.90| 0.50| 0.74|\n",
      "------------------\n",
      "-------------\n",
      "  o         \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.50| 0.55|\n",
      "------------------\n",
      " 0.50| 0.53| 0.50|\n",
      "------------------\n",
      "  x  | 0.50|  o  |\n",
      "------------------\n",
      "-------------\n",
      "  o       x \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "  x       o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "-------------\n",
      "  o       x \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "  x       o \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.50| 0.51|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.64| 0.50| 0.74|\n",
      "------------------\n",
      "-------------\n",
      "  o         \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  o  | 0.53|\n",
      "------------------\n",
      " 0.50| 0.50| 0.53|\n",
      "------------------\n",
      " 0.94| 0.80|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  o   o     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "  x       x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,2\n",
      "-------------\n",
      "  o   o   o \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "  x       x \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.50| 0.51|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.64| 0.50| 0.61|\n",
      "------------------\n",
      "-------------\n",
      "  o         \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "  x         \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.50| 0.53|\n",
      "------------------\n",
      " 0.43|  o  | 0.50|\n",
      "------------------\n",
      "  x  | 0.53| 0.94|\n",
      "------------------\n",
      "-------------\n",
      "  o         \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "  x       x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  o  | 0.67|\n",
      "------------------\n",
      " 0.55|  o  | 0.55|\n",
      "------------------\n",
      "  x  | 1.00|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  o   o     \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "  x   x   x \n",
      "-------------\n",
      "Play again? [Y/n]: n\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # train the agent\n",
    "  p1 = Agent()\n",
    "  p2 = Agent()\n",
    "\n",
    "  # set initial V for p1 and p2\n",
    "  env = Environment()\n",
    "  state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "\n",
    "  Vx = initialV_x(env, state_winner_triples)\n",
    "  p1.setV(Vx)\n",
    "  Vo = initialV_o(env, state_winner_triples)\n",
    "  p2.setV(Vo)\n",
    "\n",
    "  # give each player their symbol\n",
    "  p1.set_symbol(env.x)\n",
    "  p2.set_symbol(env.o)\n",
    "\n",
    "  #set epsilons\n",
    "  p1.set_epsalf(0.1, 0.05)\n",
    "  p2.set_epsalf(0.1, 0.05)\n",
    "\n",
    "  T = 20000\n",
    "  for t in range(T):\n",
    "    if t % 5000 == 0:\n",
    "      print(t)\n",
    "    play_game(p1, p2, Environment())\n",
    "\n",
    "  # play human vs. agent\n",
    "  # do you think the agent learned to play the game well?\n",
    "  human = Human()\n",
    "  human.set_symbol(env.o)\n",
    "  while True:\n",
    "    p1.set_verbose(True)\n",
    "    p1.set_epsalf(0.001, 0.5)\n",
    "    play_game(human, p1, Environment(), draw=2)\n",
    "    # I made the agent player 1 because I wanted to see if it would\n",
    "    # select the center as its starting move. If you want the agent\n",
    "    # to go second you can switch the human and AI.\n",
    "    answer = input(\"Play again? [Y/n]: \")\n",
    "    if answer and answer.lower()[0] == 'n':\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.50| 0.50| 0.50|\n",
      "------------------\n",
      " 0.50| 0.50|  o  |\n",
      "------------------\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "          o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.50| 0.49|\n",
      "------------------\n",
      " 0.50|  x  | 0.50|\n",
      "------------------\n",
      " 0.49| 0.50|  o  |\n",
      "------------------\n",
      "-------------\n",
      "  o   x     \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "          o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 2,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  x  | 0.47|\n",
      "------------------\n",
      " 0.45|  x  | 0.47|\n",
      "------------------\n",
      " 0.49|  o  |  o  |\n",
      "------------------\n",
      "-------------\n",
      "  o   x     \n",
      "-------------\n",
      "      x     \n",
      "-------------\n",
      "  x   o   o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  |  x  |  o  |\n",
      "------------------\n",
      " 0.30|  x  | 0.30|\n",
      "------------------\n",
      "  x  |  o  |  o  |\n",
      "------------------\n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "  x   x     \n",
      "-------------\n",
      "  x   o   o \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,2\n",
      "-------------\n",
      "  o   x   o \n",
      "-------------\n",
      "  x   x   o \n",
      "-------------\n",
      "  x   o   o \n",
      "-------------\n",
      "Play again? [Y/n]: y\n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,1\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.05| 0.07| 0.27|\n",
      "------------------\n",
      " 0.07|  o  | 0.07|\n",
      "------------------\n",
      " 0.07| 0.07| 0.07|\n",
      "------------------\n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "            \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 0,0\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.02|  x  |\n",
      "------------------\n",
      " 0.45|  o  | 0.45|\n",
      "------------------\n",
      " 0.45| 0.41| 0.46|\n",
      "------------------\n",
      "-------------\n",
      "  o       x \n",
      "-------------\n",
      "      o     \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,2\n",
      "Taking a greedy action\n",
      "------------------\n",
      "  o  | 0.32|  x  |\n",
      "------------------\n",
      " 0.01|  o  |  o  |\n",
      "------------------\n",
      " 0.32| 0.31|  x  |\n",
      "------------------\n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "      o   o \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Enter coordinates i,j for your next move (i,j=0..2): 1,0\n",
      "-------------\n",
      "  o   x   x \n",
      "-------------\n",
      "  o   o   o \n",
      "-------------\n",
      "          x \n",
      "-------------\n",
      "Play again? [Y/n]: n\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # train the agent\n",
    "  p1 = Agent()\n",
    "  p2 = Agent()\n",
    "\n",
    "  # set initial V for p1 and p2\n",
    "  env = Environment()\n",
    "  state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "\n",
    "  Vx = initialV_x(env, state_winner_triples)\n",
    "  p1.setV(Vx)\n",
    "  Vo = initialV_o(env, state_winner_triples)\n",
    "  p2.setV(Vo)\n",
    "\n",
    "  # give each player their symbol\n",
    "  p1.set_symbol(env.x)\n",
    "  p2.set_symbol(env.o)\n",
    "\n",
    "  #set epsilons\n",
    "  p1.set_epsalf(0.1, 0.05)\n",
    "  p2.set_epsalf(0.1, 0.05)\n",
    "\n",
    "  T = 20000\n",
    "  for t in range(T):\n",
    "    if t % 5000 == 0:\n",
    "      print(t)\n",
    "    play_game(p2, p1, Environment())\n",
    "\n",
    "  # play human vs. agent\n",
    "  # do you think the agent learned to play the game well?\n",
    "  human = Human()\n",
    "  human.set_symbol(env.o)\n",
    "  while True:\n",
    "    p1.set_verbose(True)\n",
    "    p1.set_epsalf(0.001, 0.5)\n",
    "    play_game(human, p1, Environment(), draw=2)\n",
    "    # I made the agent player 1 because I wanted to see if it would\n",
    "    # select the center as its starting move. If you want the agent\n",
    "    # to go second you can switch the human and AI.\n",
    "    answer = input(\"Play again? [Y/n]: \")\n",
    "    if answer and answer.lower()[0] == 'n':\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The agent is not very good at having to play defense while going second in the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  # train the agent\n",
    "  p1 = Agent()\n",
    "  p2 = Agent()\n",
    "\n",
    "  # set initial V for p1 and p2\n",
    "  env = Environment()\n",
    "  state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "\n",
    "  Vx = initialV_x(env, state_winner_triples)\n",
    "  p1.setV(Vx)\n",
    "  Vo = initialV_o(env, state_winner_triples)\n",
    "  p2.setV(Vo)\n",
    "\n",
    "  # give each player their symbol\n",
    "  p1.set_symbol(env.x)\n",
    "  p2.set_symbol(env.o)\n",
    "\n",
    "  #set epsilons\n",
    "  p1.set_epsalf(0.1, 0.5)\n",
    "  p2.set_epsalf(0.01, 0.5)\n",
    "\n",
    "  T = 20000\n",
    "  for t in range(T):\n",
    "    if t % 5000 == 0:\n",
    "      print(t)\n",
    "    play_game(p2, p1, Environment())\n",
    "\n",
    "  # play human vs. agent\n",
    "  # do you think the agent learned to play the game well?\n",
    "  human = Human()\n",
    "  human.set_symbol(env.o)\n",
    "  while True:\n",
    "    p1.set_verbose(True)\n",
    "    p1.set_epsalf(0.001, 0.5)\n",
    "    play_game(human, p1, Environment(), draw=2)\n",
    "    # I made the agent player 1 because I wanted to see if it would\n",
    "    # select the center as its starting move. If you want the agent\n",
    "    # to go second you can switch the human and AI.\n",
    "    answer = input(\"Play again? [Y/n]: \")\n",
    "    if answer and answer.lower()[0] == 'n':\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the learning rate still did not help it defending spots from me winning.\n",
    "Making p2 agent have a higher exploit rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
